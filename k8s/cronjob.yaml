apiVersion: batch/v1
kind: CronJob
metadata:
  name: threatintel-daily-report
  namespace: threat-intelligence
spec:
  schedule: "0 2 * * *"  # Daily at 2 AM UTC
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: report-generator
            image: threatintel/pipeline:latest
            command:
            - python
            - -c
            - |
              import json
              from pathlib import Path
              from datetime import datetime, timedelta

              # Generate daily quality report
              data_dir = Path("/app/data")
              reports_dir = data_dir / "quality_reports"

              yesterday = datetime.utcnow() - timedelta(days=1)
              report_files = list(reports_dir.glob(f"*_{yesterday.strftime('%Y%m%d')}*.json"))

              summary = {
                  "date": yesterday.strftime("%Y-%m-%d"),
                  "sources": {},
                  "total_items": 0,
                  "average_quality": 0.0
              }

              for report_file in report_files:
                  with open(report_file) as f:
                      report = json.load(f)
                      summary["sources"][report["source"]] = {
                          "quality_score": report["quality_score"],
                          "recommendations": report["recommendations"]
                      }

              # Save summary
              summary_file = data_dir / "daily_summaries" / f"summary_{yesterday.strftime('%Y%m%d')}.json"
              summary_file.parent.mkdir(parents=True, exist_ok=True)
              with open(summary_file, "w") as f:
                  json.dump(summary, f, indent=2)

              print(f"Daily report generated: {summary_file}")
            volumeMounts:
            - name: data
              mountPath: /app/data
          volumes:
          - name: data
            persistentVolumeClaim:
              claimName: threatintel-data-pvc
          restartPolicy: OnFailure

---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: threatintel-cleanup
  namespace: threat-intelligence
spec:
  schedule: "0 3 * * 0"  # Weekly on Sunday at 3 AM UTC
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: cleanup
            image: threatintel/pipeline:latest
            command:
            - python
            - -c
            - |
              from pathlib import Path
              from datetime import datetime, timedelta

              # Clean up old files (older than 30 days)
              data_dir = Path("/app/data")
              cutoff_date = datetime.utcnow() - timedelta(days=30)

              for subdir in ["processed", "quality_reports", "daily_summaries"]:
                  dir_path = data_dir / subdir
                  if not dir_path.exists():
                      continue

                  for file_path in dir_path.rglob("*.json"):
                      if file_path.stat().st_mtime < cutoff_date.timestamp():
                          file_path.unlink()
                          print(f"Deleted old file: {file_path}")

              print("Cleanup completed")
            volumeMounts:
            - name: data
              mountPath: /app/data
          volumes:
          - name: data
            persistentVolumeClaim:
              claimName: threatintel-data-pvc
          restartPolicy: OnFailure
